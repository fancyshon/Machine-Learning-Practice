{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aicpu Spring.ipynb","provenance":[],"collapsed_sections":["umjMDLq9IibR","IY4ygrd9zN8Y","o_Uva9ZWTO3X","ShFUG_8JHcTx","gpdz2o_2IlJL","yMCVkOY4IzRi","4As3UyKoTceo","oXGZzsDobi_4","uqqbc03fJf0N","1UcRLKNnTieQ","KtXqtaFtfJ5_"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GOw2mRCr5AGz"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"-1fg8QiGXNRQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622690942006,"user_tz":-480,"elapsed":664,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"baafb0ad-43d8-475b-a9d2-f33917e009a6"},"source":["from google.colab import drive\n","import sys\n","import os\n","drive.mount('/content/gdrive/')\n","# if not os.path.exists('/content/data'):\n","!cp -r /content/gdrive/MyDrive/Aicup_spring/data /content\n","# if not os.path.exists('/content/stopword'):\n","!cp -r /content/gdrive/MyDrive/Aicup_spring/stopword /content\n","# if not os.path.exists('/content/dataset'):\n","#   !cp -r /content/gdrive/MyDrive/Aicup_spring/dataset /content\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"umjMDLq9IibR"},"source":["# The Encoder from Transformer\n","---\n","paper link: \\\\\n","[Hierarchical Attention Networks for Document Classification](https://www.aclweb.org/anthology/N16-1174.pdf) \\\\\n","[Attention Is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n","\n"]},{"cell_type":"code","metadata":{"id":"KxiYHF5WE43s","executionInfo":{"status":"ok","timestamp":1622690939850,"user_tz":-480,"elapsed":239,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import math\n","\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_emb: int, dropout: float = 0.1, max_len: int = 200):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        # Compute the positional encodings once in log space.\n","        self.pe = torch.zeros(max_len, d_emb)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_emb, 2) *\n","                             -(math.log(10000.0) / d_emb))\n","        self.pe[:, 0::2] = torch.sin(position * div_term)\n","        self.pe[:, 1::2] = torch.cos(position * div_term)\n","        self.pe = self.pe.unsqueeze(0)\n","\n","    def forward(self, src):\n","        pe = self.pe.detach().to(src.device)\n","        output = src + pe[:, :src.size(1)]\n","        return self.dropout(output)\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_hid, n_head):\n","        super(MultiHeadAttention, self).__init__()\n","        self.n_head = n_head\n","        self.d_k = d_hid // n_head\n","        self.query = nn.Parameter(torch.randn(1, d_hid))\n","        self.key = nn.Linear(d_hid, d_hid)\n","        self.value = nn.Linear(d_hid, d_hid)\n","        self.linear = nn.Linear(d_hid, d_hid)\n","\n","    def forward(self, x, batch_tk_mask):\n","        B = x.size(0)\n","\n","        # Input  shape: `(1, Hid)`.\n","        # Output shape: `(Head, 1, K)`.\n","        q = self.query.view(-1, self.n_head, self.d_k).transpose(0, 1)\n","\n","        # Transform temporal features to query, key and value features.\n","        # Input  shape: `(B, S, Hid)`.\n","        # Output shape: `(B, Head, S, K)`.\n","        k = self.key(x).view(B, -1, self.n_head, self.d_k).transpose(1, 2)\n","        v = self.value(x).view(B, -1, self.n_head, self.d_k).transpose(1, 2)\n","\n","        # Calculate self attention scores with query and key features.\n","        # Self attention scores are scaled down by hidden dimension square\n","        # root to avoid overflow.\n","        # `q` Input  shape: `(Head, 1, K)`.\n","        # `k` Input  shape: `(B, Head, S, K)`.\n","        # Output shape: `(B, Head, 1, S)`.\n","        # print(q.shape)\n","        # print(k.shape)\n","        attn = q @ k.transpose(-1, -2) / math.sqrt(x.size(-1))\n","\n","        # Mask parts of attention scores by replacing with large negative\n","        # values.\n","        # Input  shape: `(B, Head, 1, S)`.\n","        # Output shape: `(B, Head, 1, S)`.\n","        batch_tk_mask = batch_tk_mask.repeat(self.n_head, 1, 1, 1)\n","\n","        batch_tk_mask = batch_tk_mask.transpose(0, 1)\n","        batch_tk_mask = batch_tk_mask.transpose(-1, -2)\n","        # print(attn.shape)\n","        # print(batch_tk_mask.shape)\n","        attn.masked_fill_(batch_tk_mask, -1e9)\n","\n","        # Softmax normalize on attention scores.\n","        # Large negative values will be closed to zero after normalization.\n","        # Input  shape: `(B, Head, 1, S)`.\n","        # Output shape: `(B, Head, 1, S)`.\n","        attn = F.softmax(attn, dim=-1)\n","\n","        # Use attention scores to calculate weighted sum on value features.\n","        # Then perform one more linear tranformation on weighted sum.\n","        # Finally dropout transformed features.\n","        # `attn` Input  shape: `(B, Head, 1, S)`.\n","        # `v` Input  shape: `(B, Head, S, k)`.\n","        # Output shape: `(B, Head, 1, K)`.\n","        output = attn @ v\n","\n","        # Input  shape: `(B, Head, 1, K)`.\n","        # Output shape: `(B, 1, Hid)`.\n","        output = output.transpose(1, 2).contiguous()\n","        output = output.view(B, -1, self.n_head * self.d_k)\n","\n","        # Output shape: `(B, Hid)`.\n","        return self.linear(output.squeeze(1))\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, d_emb: int, p_hid: float):\n","        super().__init__()\n","        self.linear = nn.Linear(d_emb, d_emb)\n","        self.pe = PositionalEncoding(d_emb, p_hid)\n","        self.attn_emb = MultiHeadAttention(d_emb, 4)\n","        self.layernorm1 = nn.LayerNorm(d_emb)\n","        self.layernorm2 = nn.LayerNorm(d_emb)\n","\n","    def forward(self, x: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n","        # Shape: [B, S, H]\n","        emb = self.layernorm1(self.linear(x))\n","\n","        # Shape: [B, S, H]\n","        emb = self.pe(emb)\n","\n","        # Shape: [B, H]\n","        emb = self.layernorm2(self.attn_emb(emb, mask))\n","\n","        return emb\n"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IY4ygrd9zN8Y"},"source":["# Read Stopword"]},{"cell_type":"code","metadata":{"id":"0ZIV6KbtvICt","executionInfo":{"status":"ok","timestamp":1622690937504,"user_tz":-480,"elapsed":244,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}}},"source":["f=open(os.path.join('stopword','ch_stopword.txt'),mode='r')\n","stopword_list=f.read().splitlines()\n","\n","# print(stopword_list)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_Uva9ZWTO3X"},"source":["# Dataset.py\n"]},{"cell_type":"code","metadata":{"id":"-CXEHUDwT_pP","executionInfo":{"status":"ok","timestamp":1622690935744,"user_tz":-480,"elapsed":351,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}}},"source":["import numpy as np\n","import csv\n","import json\n","import unicodedata\n","import re\n","import jieba\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","\n","\n","'''\n","Here we will do preprocessing on the dataset.\n","Something needs to be done here :\n","1. Read the file in.\n","2. Separate the article, question, answer.\n","3. Used PAD to round each sentence into the same length\n","'''\n","\n","\n","def split_sent(sentence: str):\n","    first_role_idx = re.search(':', sentence).end(0)\n","    out = [sentence[:first_role_idx]]\n","\n","    tmp = sentence[first_role_idx:]\n","    # print('sen',sentence)\n","    # print('tmp',tmp)\n","    # print('out',out)\n","    jieba.add_word(\"個管師\")\n","    jieba.add_word('性行為')\n","\n","\n","    out2=list(jieba.cut(sentence))\n","    # print('out2',out2)\n","    for i in out2:\n","      if i in stopword_list:\n","        out2.remove(i)\n","      if i=='護理師' or i=='醫師' or i=='民眾' or i=='家屬' or i=='個管師':\n","        out2.remove(i)\n","\n","    while tmp:\n","        res = re.search(\n","            r'(護理師[\\w*]\\s*:|醫師\\s*:|民眾\\s*:|家屬[\\w*]\\s*:|個管師\\s*:)', tmp)\n","        if res is None:\n","            break\n","\n","        idx = res.start(0)\n","        idx_end = res.end(0)\n","        out[-1] = list(out[-1] + tmp[:idx])\n","        out.append(tmp[idx:idx_end])\n","        tmp = tmp[idx_end:]\n","\n","        # print(\"out:\",tmp)\n","        # input()\n","\n","    out[-1] = list(out[-1] + tmp)\n","\n","\n","    # Remove stopword\n","    for i in out:\n","      if (i in stopword_list):\n","        out.remove(i)\n","    # print('out2',out2)\n","    \n","\n","    return out2\n","\n","def _read_risk(risk_file: str):\n","    article = []\n","    risk = []\n","\n","    # [[Sent_1], [Sent_2], ..., [Sent_n]]\n","    for i, line in enumerate(csv.reader(open(risk_file, \"r\", encoding=\"utf-8\"))):\n","        if i == 0:\n","            continue\n","        text = unicodedata.normalize(\"NFKC\", line[2]).replace(\" \", \"\")\n","        article.append(split_sent(text))\n","\n","        # print(risk_file)\n","        # input()\n","\n","        if risk_file != \"data/Develop_risk_classification.csv\":\n","          risk.append(int(line[3]))\n","        else:\n","          risk.append(-1)\n","\n","    return article, risk\n","\n","def _read_qa(qa_file: str):\n","    qa = {}\n","    # [Question, [[Choice_1, Answer_1], [Choice_2, Answer_2], [Choice_3, Answer_3]]]\n","    for data in json.loads(unicodedata.normalize(\"NFKC\", open(qa_file, \"r\", encoding=\"utf-8\").read())):\n","        question = data[\"question\"]\n","        choice_ans = []\n","\n","        if qa_file != \"data/Develop_QA.json\":\n","          choice_ans = [(\n","                  list(choice[\"text\"]),\n","                  int(choice[\"label\"].strip() == data[\"answer\"].strip())\n","              ) for choice in question[\"choices\"]]\n","        else:\n","          choice_ans = [(\n","                  list(choice[\"text\"]),\n","                  -1)\n","              for choice in question[\"choices\"]]\n","\n","        question_text = list(question[\"stem\"])\n","        aid = data[\"article_id\"]\n","        if aid in qa:\n","            qa[aid][1].append((question_text, choice_ans))\n","        else:\n","            qa[aid] = (split_sent(data['text'].replace(\" \", \"\")), [(question_text, choice_ans)])\n","\n","    return zip(*[v for _,v in sorted(qa.items(),key=lambda x:x[0])])\n","\n","\n","def encode_sent(w2id: dict, sentence: list, max_length: int):\n","    output = []\n","    for i, token in enumerate(sentence):\n","        if i >= max_length:\n","            break\n","        if token in w2id:\n","            output.append(w2id[token])\n","        else:\n","            output.append(0)\n","    padding_word = [0]\n","    sent_padding_size = max_length - len(output)\n","    output = output + padding_word*sent_padding_size\n","\n","    return output\n","\n","\n","def encode_articles(article_text, max_doc_len, w2id, max_sent_len):\n","    article = []\n","    for document in article_text:\n","        article.append([])\n","        for i, sentence in enumerate(document):\n","            if i >= max_doc_len:\n","                break\n","            article[-1].append([])\n","            article[-1][-1] = encode_sent(w2id, sentence, max_sent_len)\n","        padding_sent = [[0]*max_sent_len]\n","        doc_padding_size = max_doc_len - len(article[-1])\n","        article[-1] = article[-1] + padding_sent*doc_padding_size\n","    return np.array(article)\n","\n","\n","class dataset_qa(Dataset):\n","    def __init__(\n","        self,\n","        vocab_path: str,\n","        qa_file: str,\n","        max_sent_len: int = 52,\n","        max_doc_len: int = 170,\n","        max_q_len: int = 20,\n","        max_c_len: int = 18\n","    ):\n","        super().__init__()\n","        with open(vocab_path, 'r', encoding='utf-8') as f_w2id:\n","            w2id = json.load(f_w2id)\n","\n","        article_text, qa_pairs = _read_qa(qa_file)\n","\n","        # `article` shape: [N, `max_doc_len`, `max_sent_len`]\n","        self.article = encode_articles(\n","            article_text, max_doc_len, w2id, max_sent_len)\n","\n","        self.QA = []\n","        for idx, qa_pair in enumerate(qa_pairs):\n","            for question, choice_ans in qa_pair:\n","                choice, ans = zip(*choice_ans)\n","                \n","                self.QA.append({\n","                    \"article\": self.article[idx],\n","                    \"question\": np.array(encode_sent(w2id, question, max_q_len)),\n","                    \"choice\": np.array([encode_sent(w2id, x, max_c_len) for x in choice]),\n","                    \"qa_answer\": np.array(ans),\n","                })\n","        # print(self.QA['qa_answer'])\n","        # input()\n","\n","    def __len__(self):\n","        return len(self.QA)\n","\n","    def __getitem__(self, idx: int):\n","        return self.QA[idx]\n","\n","\n","class dataset_risk(Dataset):\n","    def __init__(\n","        self,\n","        vocab_path: str,\n","        risk_file: str,\n","        max_sent_len: int = 52,\n","        max_doc_len: int = 170,\n","    ):\n","        super().__init__()\n","        with open(vocab_path, 'r', encoding='utf-8') as f_w2id:\n","            w2id = json.load(f_w2id)\n","        # w2id = {\"[PAD]\": 0}\n","        article_text, risk = _read_risk(risk_file)\n","\n","        # print(article_text)\n","        # input()\n","\n","        # `risk` shape: [N]\n","        self.risk = np.array(risk, dtype=np.float32)\n","\n","        # `article` shape: [N, `max_doc_len`, `max_sent_len`]\n","        self.article = encode_articles(\n","            article_text, max_doc_len, w2id, max_sent_len)\n","        \n","        # print(self.article)\n","        # input()\n","\n","    def __len__(self):\n","        return len(self.risk)\n","\n","    def __getitem__(self, idx: int):\n","        return {\"article\": self.article[idx], \"risk_answer\": self.risk[idx]}\n"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJnPNRlMeGUO"},"source":["# Risk Classificaion"]},{"cell_type":"markdown","metadata":{"id":"ShFUG_8JHcTx"},"source":["## Take a look at the risk classification dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_dbcLoRBuIx","executionInfo":{"status":"ok","timestamp":1622544061492,"user_tz":-480,"elapsed":1755,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"1a12173c-b481-438b-9325-60059ddddbbb"},"source":["import os\n","import pandas as pd\n","import json\n","# from dataset import dataset_risk\n","\n","risk_file=os.path.join(\"data\", \"SampleData_RiskClassification.csv\")\n","print('risk data:')\n","print(pd.read_csv(risk_file,usecols=['article_id','text','label']))\n","print('\\n---------------------------------')\n","print('vocab:')\n","print(list(json.load(open(os.path.join(\"data\", \"vocab.json\"))).items())[:10])\n","\n","dataset = dataset_risk(\n","    vocab_path=os.path.join(\"data\", \"vocab.json\"),\n","    risk_file=risk_file,\n",")\n","d = next(iter(dataset))\n","print('\\n---------------------------------')\n","print('text\\n', d['article'])\n","print(d['article'].shape)\n","r = {v: k for k, v in json.load(open(os.path.join(\"data\", \"vocab.json\"))).items()}\n","print(*[''.join(map(lambda x:r[x], i))[:40] for i in d['article'][:4,:] ], sep='\\n')\n","print('\\n---------------------------------')\n","print('answer:\\n', d['risk_answer'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n"],"name":"stderr"},{"output_type":"stream","text":["risk data:\n","    article_id                                               text  label\n","0            1  個管師：這個月還好嗎？民眾：蛤？個管師：這個月還好嗎？民眾：這個月還好。個管師：還好，還可以...      1\n","1            2  個管師：所以你這個月還OK？民眾：還OK啊。個管師：那有固定伴侶嗎？民眾：沒有。個管師：你一...      1\n","2            3  個管師：其實你這樣子的吃法是吃每天嗎？民眾：對我是吃每天。個管師：啊你有固定的時間嗎？民眾：...      0\n","3            4  個管師：等一下他先填問卷，不會有聲音。民眾：哈哈哈。個管師：等一下。個管師：這兩個月還好嗎？...      0\n","4            5  個管師：這兩個月都還好嗎？民眾：目前都還好，就除了你說的HPV的狀況。個管師：恩，那問一下你...      0\n","5            6  醫師：好啦，那所以我先講，你是前二個月有抽血？民眾：對。醫師：抽血狀況看起來還可以。民眾：是...      0\n","6            7  醫師：那所以我們現在吃兩個月了嘛。民眾：對。醫師：嘿。你現在還是天天吃？民眾：對，但到目前還...      1\n","7            8  醫師：還好嗎？還可以？民眾：嗯。醫師：你今天來得這麽早欸。民眾：對啊，今天車位比較好找。醫師...      0\n","8            9  醫師：好啦。那這個月還好嗎？民眾：就……狀態是還好，只是有HPV。醫師：嗯哼。喔你看皮膚科。...      1\n","9           10  醫師：你過去兩個月吃藥是，你還是天天吃嗎？民眾：對，天天吃。醫師：所以比方說像，兩個月以內幾...      0\n","10          11  醫師：主要是做、做發燒的一些檢查，初步看有抽血還有照相，那抽血的部分阿就是，其實你的發炎指數...      0\n","11          12  醫師：啊最近的狀況還好嗎？民眾：還好啦。醫師：還好啦齁，一樣肚子還是不舒服。民眾：肚子會悶，...      0\n","12          13  醫師：我們接下來會慢慢的把那個，因為吃很多藥都吃兩年了，那吃了兩年的藥我把它減掉，因為這樣身...      1\n","13          14  醫師：謝謝你這樣幫忙他們這樣，那最近還好嗎？民眾：就是因為不太好所以才要再回診，因為我為甚麼...      1\n","14          15  民眾：黃醫師我是想要請問你那個，阿之前腎盂炎住院的時候你有發現我有腎臟的水泡的問題，對，然後...      0\n","15          16  醫師：你有做超音波嘛，那我們來看報告，有些部分有紅字耶。民眾：紅字是甚麼意思？醫師：就是肝功...      1\n","16          17  民眾：也有點不舒服，可是就是腰這邊有也一點點痛，我脫起來我想……。醫師：來我看一下。民眾：看...      0\n","17          18  醫師：都ＯＫ拉齁？民眾：都ＯＫ。醫師：阿吃藥有沒有什麼不舒服？民眾：沒有。醫師：也都沒有這樣...      1\n","18          19  醫師：阿這次還好嗎？民眾：這次沒有抽血阿。醫師：這次還，阿血壓那些都還OK啦？民眾：都還OK...      0\n","19          20  醫師：那個，吃藥還Ok嗎？民眾：OK。醫師：沒什麼問題？民眾：沒有。醫師：我們這次CD4是3...      0\n","\n","---------------------------------\n","vocab:\n","[('[PAD]', 0), ('，', 1), ('的', 2), ('。', 3), ('、', 4), ('是', 5), ('一', 6), ('在', 7), ('：', 8), ('了', 9)]\n"],"name":"stdout"},{"output_type":"stream","text":["Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.850 seconds.\n","Prefix dict has been built successfully.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","---------------------------------\n","text\n"," [[ 108    0    0 ...    0    0    0]\n"," [ 204   49    0 ...    0    0    0]\n"," [1007    0    0 ...    0    0    0]\n"," ...\n"," [ 126    0    0 ...    0    0    0]\n"," [  92    0    0 ...    0    0    0]\n"," [ 826    0    0 ...    0    0    0]]\n","(170, 52)\n","月[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD\n","還好[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n","蛤[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD\n","月[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD\n","\n","---------------------------------\n","answer:\n"," 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gpdz2o_2IlJL"},"source":["## Risk Classification model"]},{"cell_type":"code","metadata":{"id":"44rSfBEZHnGQ"},"source":["class Risk_Classifier(nn.Module):\n","    def __init__(self, d_emb: int, p_drop: float, n_layers: int):\n","        super().__init__()\n","        hid = []\n","        self.l0 = nn.Linear(d_emb, d_emb)\n","        for _ in range(n_layers):\n","            hid.append(nn.Linear(in_features=d_emb, out_features=d_emb))\n","            hid.append(nn.ReLU())\n","            hid.append(nn.Dropout(p=p_drop))\n","        self.hid = nn.Sequential(*hid)\n","        self.l1 = nn.Linear(d_emb, d_emb//2)\n","        self.dropout = nn.Dropout(p_drop)\n","        self.l2 = nn.Linear(d_emb//2, 1)\n","\n","    def forward(self, document: torch.Tensor) -> torch.Tensor:\n","        output = document\n","        output = self.l0(output)\n","\n","        output = self.hid(output)\n","        #　Linear layer\n","        # Input shape: `(B, E)`\n","        # Ouput shape: `(B, E//2)`\n","        # output = F.relu(self.l1(document))\n","        output = F.relu(self.l1(output))\n","\n","        #　Dropout\n","        # Input shape: `(B, E//2)`\n","        # Ouput shape: `(B, E//2)`\n","        # output = self.dropout(output)\n","\n","        #　Linear layer\n","        # Input shape: `(B, E//2)`\n","        # Ouput shape: `(B, 1)`\n","        output = torch.sigmoid(self.l2(output))\n","\n","        return output.squeeze(-1)\n","\n","\n","class risk_model(nn.Module):\n","    def __init__(self, embedding_path: str, d_emb: int, n_cls_layers: int, p_drop: float):\n","        super().__init__()\n","        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(\n","            np.load(embedding_path)), freeze=True, padding_idx=0)\n","        self.word_encoder = Encoder(d_emb, p_drop)\n","        self.encoder = Encoder(d_emb, p_drop)\n","        self.risk = Risk_Classifier(d_emb, p_drop, n_cls_layers)\n","\n","    def forward(self, document):\n","        # Embedding layer\n","        # Shape: [B, `max_doc_len`, `max_sent_len`, E]\n","        doc = self.embedding(document)\n","        w_mask, s_mask = self.create_mask(document)\n","\n","        # Sentence embedding\n","        # Input shape: [B, `max_doc_len`, `max_sent_len`, E]\n","        # Output shape: [B, `max_doc_len`, E]\n","        doc = torch.stack([ self.word_encoder(d,w) for d,w in zip(doc, w_mask)])\n","\n","        # Document embedding\n","        # Input shape: [B, `max_doc_len`, E]\n","        # Output shape: [B, E]\n","        doc = self.encoder(doc, s_mask)\n","\n","        risk_output = self.risk(doc)\n","\n","        return risk_output\n","\n","    @staticmethod\n","    def create_mask(batch_prev_tkids: torch.Tensor) -> torch.Tensor:\n","        # Create padding self attention masks.\n","        # Shape: [B, `max_doc_len`, `max_sent_len`, 1]\n","        # Output dtype: `torch.bool`.\n","        w_pad_mask = batch_prev_tkids == 0\n","        w_pad_mask = w_pad_mask.unsqueeze(-1)\n","\n","        s_pad_mask = batch_prev_tkids.sum(dim=-1)\n","        s_pad_mask = s_pad_mask == 0\n","        s_pad_mask = s_pad_mask.unsqueeze(-1)\n","\n","        return w_pad_mask, s_pad_mask\n","\n","    def loss_fn(self, document, risk):\n","        pred_risk = self(document)\n","        pred_risk = pred_risk.reshape(-1)\n","        risk = risk.reshape(-1)\n","        return F.binary_cross_entropy(pred_risk, risk)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yMCVkOY4IzRi"},"source":["## Training Risk Classifier"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"JKqNXRyEH1o9","executionInfo":{"status":"error","timestamp":1622690441358,"user_tz":-480,"elapsed":11365,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"5a2cea34-0023-4a5b-a3e7-4957b715efdb"},"source":["import csv\n","import os\n","import pathlib\n","import re\n","\n","import numpy as np\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import roc_auc_score\n","\n","def risk_train(model_cfg, dataset, device,  # model and datasets\n","               p_drop, n_epoch, batch_size, learning_rate,  # training hyper parameter\n","               save_step, model_path):  # saving model\n","\n","    model = risk_model(**model_cfg, p_drop=p_drop).train().to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    dataldr = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    def save_model(md, step):\n","      if step!=-1:\n","        torch.save(md.state_dict(), os.path.join(model_path, f\"model-{step}.pt\"))\n","      else:\n","        torch.save(md.state_dict(), os.path.join(model_path, f\"final_model.pt\"))\n","\n","    # Train loop\n","    step = 0\n","    for epoch in range(n_epoch):\n","        tqdm_dldr = tqdm(dataldr)\n","\n","        avg_loss = 0\n","        for epoch_step, batch_data in enumerate(tqdm_dldr):\n","            optimizer.zero_grad()\n","\n","            batch_document = batch_data[\"article\"].to(device)\n","            batch_risk = batch_data[\"risk_answer\"].to(device)\n","\n","            loss = model.loss_fn(batch_document, batch_risk)\n","            loss.backward()\n","            optimizer.step()\n","\n","            step += 1\n","            avg_loss += loss\n","            tqdm_dldr.set_description(\n","                f\"epoch:{epoch},{step} loss:{avg_loss / (epoch_step+1):.04f}\")\n","\n","            # if step % save_step == 0:\n","                # save_model(model, step)\n","            if avg_loss / (epoch_step+1) < 0.4 and step % save_step == 0 and avg_loss / (epoch_step+1) >= 0.3:\n","                save_model(model, step)\n","                break\n","\n","    save_model(model, -1)\n","\n","\n","random_seed = 42\n","# Set random states for reproducibility\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(random_seed)\n","# Use cuda when possible\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Save training configuration\n","risk_model_path = os.path.join(\"exp\", \"risk\")\n","pathlib.Path(risk_model_path).mkdir(parents=True, exist_ok=True)\n","\n","\n","model_cfg = {\n","    \"embedding_path\": os.path.join(\"data\", \"embeddings.npy\"),\n","    \"d_emb\": 300,\n","    \"n_cls_layers\": 2,\n","}\n","\n","dataset = dataset_risk(\n","    vocab_path=os.path.join(\"data\", \"vocab.json\"),\n","    risk_file=os.path.join(\"data\", \"Train_risk_classification_ans.csv\"),\n",")\n","\n","risk_train(\n","    model_cfg=model_cfg,\n","    dataset=dataset,\n","    model_path=risk_model_path,\n","    device=device,\n","    # Hyperparameters\n","    batch_size=10,\n","    learning_rate=1e-4,\n","    n_epoch=40,\n","    save_step=100,\n","    p_drop=0.1,\n",")\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.827 seconds.\n","Prefix dict has been built successfully.\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-2147588ba5b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0msave_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mp_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-2147588ba5b5>\u001b[0m in \u001b[0;36mrisk_train\u001b[0;34m(model_cfg, dataset, device, p_drop, n_epoch, batch_size, learning_rate, save_step, model_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m                save_step, model_path):  # saving model\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'risk_model' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"Z-m10B49d3tN"},"source":["## Test on trained model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwdzhytjdDxg","executionInfo":{"status":"ok","timestamp":1622690587199,"user_tz":-480,"elapsed":261,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"6bdeafe0-5ee1-4c9e-e658-5d3b6667348c"},"source":["from sklearn.metrics import accuracy_score\n","\n","def save_result(output_path: str, data: list, ckpt: int):\n","\n","  if ckpt!=-1:\n","    output = [[\"id\", \"label\"]] + \\\n","        [[i+1, label] for i, label in enumerate(data)]\n","    csv.writer(open(os.path.join(\n","        output_path, f\"decision_{ckpt}.csv\"), 'w', newline='')).writerows(output)\n","  else:\n","    if output_path.find('risk')!=-1:\n","      output = [[\"article_id\", \"probability\"]] + \\\n","        [[i+1, label] for i, label in enumerate(data)]\n","      csv.writer(open(os.path.join(\n","        output_path, f\"decision.csv\"), 'w', newline='')).writerows(output)\n","    elif output_path.find('qa')!=-1:\n","      output = [[\"id\", \"answer\"]] + \\\n","        [[i+1, 'A' if label==0 else 'B' if label==1 else 'C'] for i, label in enumerate(data)]\n","      csv.writer(open(os.path.join(\n","        output_path, f\"qa.csv\"), 'w', newline='')).writerows(output)\n","        \n","@torch.no_grad()\n","def risk_test(model_cfg, dataset, device, batch_size,\n","              model_path, output_path):\n","    dataldr = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=False)\n","\n","    # Load all checkpoints\n","    ckpts = sorted([\n","        (int(ckpt.group(1)), os.path.join(risk_model_path, ckpt.group(0)))\n","        for ckpt in map(lambda f:re.match(r'model-(\\d+).pt', f), os.listdir(model_path))\n","        if ckpt is not None\n","    ], key=lambda x: x[0])\n","\n","    for step, ckpt in ckpts:\n","        # Model\n","        model = risk_model(**model_cfg, p_drop=0.0)\n","        model.load_state_dict(torch.load(ckpt))\n","        model = model.eval().to(device)\n","\n","        preds = []\n","\n","        for batch_data in tqdm(dataldr):\n","            batch_document = batch_data[\"article\"].to(device)\n","            preds += model(batch_document).tolist()\n","        print(f\"\\nroc_auc {step} : {roc_auc_score(dataset.risk, preds):.04f}\", flush=True)\n","        save_result(output_path, preds, step)    \n","\n","risk_output_path = os.path.join(\"output\", \"risk\")\n","pathlib.Path(risk_output_path).mkdir(parents=True, exist_ok=True)\n","\n","print(\"\\nevaluate on training set...\", flush=True)\n","risk_test(\n","    model_cfg=model_cfg,\n","    dataset=dataset,\n","    model_path=risk_model_path,\n","    device=device,\n","    batch_size=8,\n","    output_path=risk_output_path,\n",")\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\n","evaluate on training set...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4As3UyKoTceo"},"source":["## Risk Predict"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIFdof8QTib8","executionInfo":{"status":"ok","timestamp":1622545209674,"user_tz":-480,"elapsed":2795,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"f34edca2-5823-4520-84ae-af39d1657028"},"source":["def risk_predict(model_cfg, dataset, device, batch_size,\n","              model_path, output_path):\n","    dataldr = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=False)\n","    \n","    model = risk_model(**model_cfg, p_drop=0.0)\n","    # print(os.path.join(risk_model_path,'final_model.pt'))\n","    # input()\n","    model.load_state_dict(torch.load('exp/risk/final_model.pt'))\n","    model = model.eval().to(device)\n","\n","    preds = []\n","\n","    for batch_data in tqdm(dataldr):\n","        batch_document = batch_data[\"article\"].to(device)\n","        preds += model(batch_document).tolist()\n","        # print(batch_data[\"article\"])\n","    save_result(output_path, preds, -1)\n","\n","test_data=dataset_risk(\n","    vocab_path=os.path.join(\"data\", \"vocab.json\"),\n","    risk_file=os.path.join(\"data\", \"Develop_risk_classification.csv\"),\n",")\n","final_result_path=os.path.join(\"result\", \"risk\")\n","pathlib.Path(final_result_path).mkdir(parents=True, exist_ok=True)\n","\n","\n","print(\"\\nevaluate on test set...\", flush=True)\n","risk_predict(\n","    model_cfg=model_cfg,\n","    dataset=test_data,\n","    model_path=risk_model_path,\n","    device=device,\n","    batch_size=8,\n","    output_path=final_result_path,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","evaluate on test set...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 13/13 [00:00<00:00, 36.16it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"HAoi91QjetnA"},"source":["# Question Answer"]},{"cell_type":"markdown","metadata":{"id":"oXGZzsDobi_4"},"source":["## About Question Answer dataset"]},{"cell_type":"code","metadata":{"id":"00Cgyn8NVs99","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622691028061,"user_tz":-480,"elapsed":959,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"9acb5f52-0bad-4389-bbed-a797d42f6985"},"source":["from pprint import pprint\n","# from dataset import dataset_qa\n","\n","qa_file=os.path.join(\"data\", \"SampleData_QA.json\")\n","\n","print('qa data:')\n","pprint(json.load(open(qa_file))[0])\n","\n","dataset = dataset_qa(\n","    vocab_path=os.path.join(\"data\", \"vocab.json\"),\n","    qa_file=qa_file,\n",")\n","\n","d = next(iter(dataset))\n","print('\\n---------------------------------')\n","print('encoded article')\n","print(d['article'])\n","print(d['article'].shape)\n","print('\\n---------------------------------')\n","print('encoded question')\n","print(d['question'])\n","print(d['question'].shape)\n","print('\\n---------------------------------')\n","print('encoded choice')\n","print(d['choice'])\n","print(d['choice'].shape)\n","print('\\n---------------------------------')\n","print('answer')\n","print(d['qa_answer'])\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["qa data:\n","{'answer': 'C',\n"," 'article_id': 1,\n"," 'id': 1,\n"," 'question': {'choices': [{'label': 'A', 'text': '有固炮'},\n","                          {'label': 'B', 'text': '民眾的固砲不一定會戴套'},\n","                          {'label': 'C', 'text': '覺得PrEP沒效'}],\n","              'stem': '下列關於民眾的敘述，何者有誤？'},\n"," 'text': '個管師：這個月還好嗎？民眾：蛤？個管師：這個月還好嗎？民眾：這個月還好。個管師：還好，還可以有性行為嗎？民眾：有。個管師：所以是跟固定伴侶嗎？民眾：對。個管師：固定伴侶喔？民眾：對阿。個管師：喔，你有固定伴侶囉？民眾：本來就有，只是比較忙，所以很少約。個管師：喔，所以一直都是那一個？民眾：恩，對。個管師：诶，不對阿，你後來有用他的，然後後來扮相，後來不是不跟他，沒有跟他了嗎？民眾：用他的什麼？個管師：那個阿，他的那個，身分。吃PrEP。民眾：喔，沒有，他是我朋友。個管師：對。民眾：阿我們沒有那個。個管師：好，對。民眾：對，沒有做。個管師：好，然後所以你那時候就一直是跟現在這個嗎？民眾：對對對。個管師：12月那時候？民眾：對，阿只是之前不夠的話會跟我朋友拿。阿我朋友都剛好沒有在吃，因為他就也很少在。個管師：OK。民眾：他只要說戴套的話就不會吃那個，所以一直沒有做。個管師：喔，所以戴套跟，戴套跟PrEP你們都會二擇一？民眾：恩，他是這樣子。個管師：啊那你？民眾：阿我是可能有時候沒有戴套的話。個管師：恩。民眾：會怕的，如果對方。個管師：所以你現在都是約的喔？阿你有固炮了還約？民眾：固炮，固炮是固炮，可是我，他跟我講說他在外面沒有幹嘛，你會相信嗎？我不會相信他。個管師：所以你不相信？民眾：對阿。個管師：所以你跟這個是固炮？你固炮多久了？民眾：五、六年了吧。個管師：喔你這個這麼久了？民眾：對阿，可是很少約啦。所以有時候他會約我也都是跟他說很忙很忙。可能七、八個月約一次，可是我也不曉得說七、八個月你都不會想幹嘛阿，對阿。個管師：那這七、八個月你會想幹嘛嗎？民眾：我不會想幹嘛耶。個管師：所以你也不會主動約他，都他去主動約你？民眾：對。個管師：然後，但是你們如果，你們基本上都會吃PrEP？民眾：他不會吃啦。個管師：我說你。民眾：喔，我忘記。個管師：你會吃PrEP，然後你會戴套？民眾：對。個管師：喔。民眾：戴套嗎？個管師：對，戴套。民眾：全程嗎？個管師：對。民眾：如果說全程的話，應該也是沒有。個管師：那如果沒有戴套是他要求的還是你要求的？民眾：當然是他的，哪有可能是我，哈哈哈。個管師：他不喜歡戴套？民眾：對。個管師：喔，所以反而他就要求不戴套，你就覺得OK？民眾：也沒有覺得OK，我就覺得說⋯⋯個管師：但是還是會套他的？民眾：對阿。個管師：恩哼，那這個PrEP會你在吃，因為你是吃任務型嗎？民眾：嗯，所以就導致說有的話⋯⋯個管師：嗯。民眾：跟他約的話我才會吃。個管師：恩哼，所以那你上個月吃幾組？民眾：上個月吃，兩組吧。個管師：你吃兩組。民眾：對。個管師：恩哼，好，那反正你現在就是跟固炮，然後跟他不一定會戴保險套，因為有時候他自己會要求不要戴。民眾：恩。個管師：嗯哼，反正他不要戴你就會覺得沒關係反正你有在吃藥。民眾：對。個管師：OK。民眾：然後我會吃比較多天啦，就是說可能，不是說二一一嗎？個管師：對。民眾：我可能吃二一一一一。個管師：所以你就會多吃一天。民眾：兩天，或可能還再多吃兩天。個管師：恩哼，所以對你來說，吃PrEP對你來說會不會比較有安全感？就是在無套性行為上面，可能你以前也會無套現在也會無套。民眾：就是不會。個管師：不會嗎？那你幹嘛多吃一天？民眾：蛤？個管師：如果沒差你為什麼要多吃一天？民眾：沒有，我是說沒有安全感，所以我會再多吃幾天。個管師：對阿，所以我就說，所以我才說在沒有吃PrEP之前阿。民眾：嘿。個管師：那你無套跟吃了PrEP之後的無套的擔心是不是有差？民眾：是有差。個管師：是有差。民眾：對。個管師：所以你還是會覺得吃了PrEP之後，你無套會比較不會那麼害怕？民眾：恩。個管師：對，所以PrEP對你來說還是有效的？民眾：恩。個管師：恩哼，好喔。然後你吃任務型，還是一樣會情境問你一下啦。民眾：恩。個管師：就是，你還是會在性行為之前吃幾顆？民眾：兩顆。個管師：然後，性行為之後？民眾：一顆。個管師：嗯哼。民眾：對阿。個管師：性行為之後隔天，就二十四小時後吃一顆？民眾：對。個管師：然後再二十四小時？民眾：再吃一顆。個管師：再吃一顆，然後你會吃到再一個二十四小時？民眾：甚至兩個二十四小時。個管師：喔，就是你會覺得比較擔心。民眾：對。個管師：OK，好的。所以你還是沒有很相信你的固炮？民眾：恩。個管師：但我覺得這樣是好的，因為保護自己。因為PrEP本來就不是吃給對方看的，不是一個證明文件說我有在吃PrEP，我很好。從來都不是這件事。PrEP其實吃都是為了保護自己不被感染，對呀。好喔，阿你有沒有什麼問題要問我？民眾：沒有。個管師：有想到什麼問題嗎？民眾：想到什麼問題嗎？個管師：所以你都假日待在家裡玩，還是一樣用那個⋯⋯民眾：跟朋友吃去玩比較多啦，因為跟朋友出去玩就比較不會想要約。個管師：喔喔。民眾：對。個管師：所以你幾乎都跟朋友出去玩？民眾：對。個管師：然後都不太會約，你們不是都會去看黑板樹嗎？民眾：看黑板樹阿，或是他們最近每星期三四來我這打牌，二三四。個管師：打什麼牌？民眾：就打橋牌阿。個管師：橋牌。民眾：沒有玩錢的。個管師：所以，在你，反正現階段就是你假日幾乎都在家，跟朋友。民眾：對。個管師：然後你不見得會主動去找你的固炮？民眾：我從來不會主動去找，因為我禮拜二到禮拜六上班阿。個管師：恩。民眾：所以我就，不太想說，他十一點過後然後來我家幹嘛。個管師：喔。民眾：對阿，而且又清床很麻煩，就是要整理。有時候甚至是很討厭。個管師：所以其實你不喜歡做的原因，有一部分原因是來自於後面整理床的過程。民眾：對。個管師：好，了解。那這次聽起來覺得你還會，還OK啦，還會保護自己，也沒有太大的擔心的地方。那原則上還是希望說保險套還是要跟那個PrEP的預防藥，兩個都並行這樣。'}\n","\n","---------------------------------\n","encoded article\n","[[ 108    0    0 ...    0    0    0]\n"," [ 204   49    0 ...    0    0    0]\n"," [1007    0    0 ...    0    0    0]\n"," ...\n"," [ 126    0    0 ...    0    0    0]\n"," [  92    0    0 ...    0    0    0]\n"," [ 826    0    0 ...    0    0    0]]\n","(170, 52)\n","\n","---------------------------------\n","encoded question\n","[ 56 416 445  70 420 666   2 975 987   0 348 144  12 879  59   0   0   0\n","   0   0]\n","(20,)\n","\n","---------------------------------\n","encoded choice\n","[[ 12 708 650   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [420 666   2 708 906  11   6 251 126 423 199   0   0   0   0   0   0   0]\n"," [407  76 584 788 545 584 189 771   0   0   0   0   0   0   0   0   0   0]]\n","(3, 18)\n","\n","---------------------------------\n","answer\n","[0 0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uqqbc03fJf0N"},"source":["## Question Answer Model"]},{"cell_type":"code","metadata":{"id":"5HeAcN6DJbjb","executionInfo":{"status":"ok","timestamp":1622691028061,"user_tz":-480,"elapsed":6,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}}},"source":["class QA_Classifier(nn.Module):\n","    def __init__(self, d_emb: int, p_hid: float, n_layers: int):\n","        super().__init__()\n","        self.l1 = nn.Linear(3*d_emb, d_emb)\n","        self.dropout = nn.Dropout(p_hid)\n","\n","        hid = []\n","        for _ in range(n_layers):\n","            hid.append(nn.Linear(in_features=d_emb, out_features=d_emb))\n","            hid.append(nn.ReLU())\n","            hid.append(nn.Dropout(p=p_hid))\n","        self.hid = nn.Sequential(*hid)\n","        self.l2 = nn.Linear(d_emb, 1)\n","\n","    def forward(\n","        self,\n","        document: torch.Tensor,\n","        question: torch.Tensor,\n","        choice: torch.Tensor\n","    ) -> torch.Tensor:\n","        # Concatenates `document embedding`, `question embedding`\n","        # and `choice embeding`\n","        # Input shape: `(B, E)`, `(B, E)`, `(B, E)`\n","        # Ouput shape: `(B, 3*E)`\n","        output = torch.cat((document, question, choice), -1)\n","\n","        #　Linear layer\n","        # Input shape: `(B, 3*E)`\n","        # Ouput shape: `(B, E)`\n","        output = F.relu(self.l1(output))\n","\n","        #　Dropout\n","        # Input shape: `(B, E)`\n","        # Ouput shape: `(B, E)`\n","        output = self.dropout(output)\n","\n","        # Hidden layer\n","        output = self.hid(output)\n","\n","        #　Linear layer\n","        # Input shape: `(B, E)`\n","        # Ouput shape: `(B, 1)`\n","        output = torch.sigmoid(self.l2(output))\n","\n","        return output\n","\n","\n","class qa_model(nn.Module):\n","    def __init__(self, embedding_path: str, d_emb: int, n_cls_layers: int, p_drop: float):\n","        super().__init__()\n","        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(\n","            np.load(embedding_path)), freeze=True, padding_idx=0)\n","        self.word_encoder = Encoder(d_emb, p_drop)\n","        self.encoder = Encoder(d_emb, p_drop)\n","        self.qa = QA_Classifier(d_emb, p_drop, n_cls_layers)\n","\n","    def forward(self, document, question, choice):\n","        # Embedding layer\n","        # Shape: [B, `max_doc_len`, `max_sent_len`, E]\n","        doc = self.embedding(document)\n","        # Shape: [B, `max_q_len`, E]\n","        qst = self.embedding(question)\n","        # Shape: [B, 3, `max_c_len`, E]\n","        chs = self.embedding(choice)\n","\n","        # Sentence embedding\n","        # Shape: [B, `max_doc_len`, E]\n","        w_mask, s_mask = self.create_mask(document)\n","        \n","        doc = torch.stack([self.word_encoder(d, m) for d, m in zip(doc, w_mask)])\n","\n","        # Shape: [B, E]\n","        w_mask, _ = self.create_mask(question)\n","        qst = self.word_encoder(qst, w_mask)\n","\n","        # Document embedding\n","        # Input shape: [B, `max_doc_len`, E]\n","        # Output shape: [B, E]\n","        doc = self.encoder(doc, s_mask)\n","\n","        # Input Shape: [3, B, E]\n","        # Output Shape: [[B],[B],[B]]\n","        chs = chs.transpose(0, 1)\n","        w_mask, _ = self.create_mask(choice.transpose(0, 1))\n","        qa_output = [self.qa(doc, qst, self.word_encoder(ci, wmi)) for ci, wmi in zip(chs, w_mask)]\n","        qa_output = torch.cat(qa_output, dim=-1)\n","        return qa_output\n","\n","    def create_mask(self, batch_prev_tkids: torch.Tensor) -> torch.Tensor:\n","        # Create padding self attention masks.\n","        # Shape: [B, `max_doc_len`, `max_sent_len`, 1]\n","        # Output dtype: `torch.bool`.\n","        w_pad_mask = batch_prev_tkids == 0\n","        w_pad_mask = w_pad_mask.unsqueeze(-1)\n","\n","        s_pad_mask = batch_prev_tkids.sum(dim=-1)\n","        s_pad_mask = s_pad_mask == 0\n","        s_pad_mask = s_pad_mask.unsqueeze(-1)\n","\n","        return w_pad_mask, s_pad_mask\n","\n","    def loss_fn(self, document, question, choice, qa):\n","        pred_qa = self(document, question, choice)\n","        pred_qa = pred_qa.reshape(-1)\n","        qa = qa.reshape(-1)\n","        return F.binary_cross_entropy(pred_qa, qa)\n"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1UcRLKNnTieQ"},"source":["## Training Question Answer Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltrPn9GCToB6","executionInfo":{"status":"ok","timestamp":1622691302274,"user_tz":-480,"elapsed":87278,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"e0048073-301b-43ac-a2ce-21fe512a0b37"},"source":["def qa_train(model_cfg, dataset, device,  # model and datasets\n","             p_drop, n_epoch, batch_size, learning_rate,  # training hyper parameter\n","             save_step, model_path):  # saving model\n","\n","    model = qa_model(**model_cfg, p_drop=p_drop).train().to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    dataldr = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    def save_model(md, step):\n","      if step != -1:\n","        torch.save(md.state_dict(), os.path.join(\n","            model_path, f\"model-{step}.pt\"))\n","      else:\n","        torch.save(md.state_dict(), os.path.join(\n","            model_path, f\"final_model.pt\"))\n","\n","    # Train loop\n","    step = 0\n","    for epoch in range(n_epoch):\n","        tqdm_dldr = tqdm(dataldr)\n","\n","        avg_loss = 0\n","        for epoch_step, batch_data in enumerate(tqdm_dldr):\n","            optimizer.zero_grad()\n","            loss = model.loss_fn(\n","                document=torch.LongTensor(batch_data['article']).to(device),\n","                question=batch_data[\"question\"].to(device),\n","                choice=batch_data[\"choice\"].to(device),\n","                qa=batch_data[\"qa_answer\"].float().to(device))\n","            loss.backward()\n","            optimizer.step()\n","\n","            step += 1\n","            avg_loss += loss\n","            tqdm_dldr.set_description(\n","                f\"epoch:{epoch},step:{step}, loss:{avg_loss / (epoch_step+1):.04f}\")\n","\n","            if avg_loss / (epoch_step+1) < 0.35 and step % save_step == 0 and avg_loss / (epoch_step+1) >= 0.25:\n","                save_model(model, step)\n","                break\n","\n","    save_model(model, -1)\n","\n","\n","random_seed = 42\n","# Set random states for reproducibility\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(random_seed)\n","# Use cuda when possible\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Save training configuration\n","qa_model_path = os.path.join(\"exp\", \"qa\")\n","pathlib.Path(qa_model_path).mkdir(parents=True, exist_ok=True)\n","\n","dataset = dataset_qa(\n","    vocab_path=os.path.join(\"data\", \"vocab.json\"),\n","    qa_file=os.path.join(\"data\", \"Train_qa_ans.json\"),\n",")\n","\n","model_cfg = {\n","    \"embedding_path\": os.path.join(\"data\", \"embeddings.npy\"),\n","    \"d_emb\": 300,\n","    \"n_cls_layers\": 2,\n","}\n","\n","qa_train(\n","    model_cfg=model_cfg,\n","    dataset=dataset,\n","    model_path=qa_model_path,\n","    device=device,\n","    # Hyperparameters\n","    batch_size=10,\n","    learning_rate=1e-4,\n","    n_epoch=20,\n","    save_step=18,\n","    p_drop=0.0,\n",")\n","\n"],"execution_count":34,"outputs":[{"output_type":"stream","text":["epoch:0,step:70, loss:0.6399: 100%|██████████| 70/70 [00:05<00:00, 13.58it/s]\n","epoch:1,step:140, loss:0.6329: 100%|██████████| 70/70 [00:05<00:00, 13.78it/s]\n","epoch:2,step:210, loss:0.6221: 100%|██████████| 70/70 [00:05<00:00, 13.80it/s]\n","epoch:3,step:280, loss:0.6100: 100%|██████████| 70/70 [00:05<00:00, 13.69it/s]\n","epoch:4,step:350, loss:0.6000: 100%|██████████| 70/70 [00:05<00:00, 13.67it/s]\n","epoch:5,step:420, loss:0.5873: 100%|██████████| 70/70 [00:05<00:00, 13.57it/s]\n","epoch:6,step:490, loss:0.5762: 100%|██████████| 70/70 [00:05<00:00, 13.57it/s]\n","epoch:7,step:560, loss:0.5621: 100%|██████████| 70/70 [00:05<00:00, 13.49it/s]\n","epoch:8,step:630, loss:0.5450: 100%|██████████| 70/70 [00:05<00:00, 13.48it/s]\n","epoch:9,step:700, loss:0.5185: 100%|██████████| 70/70 [00:05<00:00, 13.46it/s]\n","epoch:10,step:770, loss:0.4896: 100%|██████████| 70/70 [00:05<00:00, 13.44it/s]\n","epoch:11,step:840, loss:0.4625: 100%|██████████| 70/70 [00:05<00:00, 13.40it/s]\n","epoch:12,step:846, loss:0.3246:   6%|▌         | 4/70 [00:00<00:05, 12.24it/s]\n","  0%|          | 0/70 [00:00<?, ?it/s]\u001b[A\n","epoch:12,step:846, loss:0.3246:   6%|▌         | 4/70 [00:00<00:08,  8.05it/s]\n","epoch:13,step:916, loss:0.4354: 100%|██████████| 70/70 [00:05<00:00, 13.42it/s]\n","epoch:14,step:918, loss:0.3425:   0%|          | 0/70 [00:00<?, ?it/s]\n","  0%|          | 0/70 [00:00<?, ?it/s]\u001b[A\n","epoch:14,step:918, loss:0.3425:   0%|          | 0/70 [00:00<?, ?it/s]\n","epoch:15,step:988, loss:0.3944: 100%|██████████| 70/70 [00:05<00:00, 13.36it/s]\n","epoch:16,step:990, loss:0.3068:   0%|          | 0/70 [00:00<?, ?it/s]\n","  0%|          | 0/70 [00:00<?, ?it/s]\u001b[A\n","epoch:16,step:990, loss:0.3068:   0%|          | 0/70 [00:00<?, ?it/s]\n","epoch:17,step:1008, loss:0.3491:  23%|██▎       | 16/70 [00:01<00:04, 13.31it/s]\n","  0%|          | 0/70 [00:00<?, ?it/s]\u001b[A\n","epoch:17,step:1008, loss:0.3491:  23%|██▎       | 16/70 [00:01<00:04, 11.55it/s]\n","epoch:18,step:1026, loss:0.2736:  23%|██▎       | 16/70 [00:01<00:04, 13.11it/s]\n","  0%|          | 0/70 [00:00<?, ?it/s]\u001b[A\n","epoch:18,step:1026, loss:0.2736:  23%|██▎       | 16/70 [00:01<00:04, 11.44it/s]\n","epoch:19,step:1044, loss:0.3178:  23%|██▎       | 16/70 [00:01<00:04, 11.46it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"KtXqtaFtfJ5_"},"source":["## Test on trained QA model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":772},"id":"GwmxjtuXfACX","executionInfo":{"status":"error","timestamp":1622691322373,"user_tz":-480,"elapsed":13522,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"4de17493-06e8-4e58-ca93-bea4ebb733d3"},"source":["from sklearn.metrics import accuracy_score\n","\n","def qa_test(model_cfg, dataset, device, batch_size,\n","            model_path, output_path):\n","    dataldr = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=False)\n","\n","    # Load all checkpoints\n","    ckpts = sorted([\n","        (int(ckpt.group(1)), os.path.join(model_path, ckpt.group(0)))\n","        for ckpt in map(lambda f:re.match(r'model-(\\d+).pt', f), os.listdir(model_path))\n","        if ckpt is not None\n","    ], key=lambda x: x[0])\n","\n","    for step, ckpt in ckpts:\n","        model = qa_model(**model_cfg, p_drop=0.0)\n","        model.load_state_dict(torch.load(ckpt))\n","        model = model.eval().to(device)\n","\n","        answer = []\n","        preds = []\n","        for batch_data in tqdm(dataldr):\n","            answer += batch_data[\"qa_answer\"].argmax(dim=-1).tolist()\n","            pred_qa = model(\n","                document=torch.LongTensor(batch_data['article']).to(device),\n","                question=batch_data[\"question\"].to(device),\n","                choice=batch_data[\"choice\"].to(device))\n","            preds += pred_qa.argmax(dim=-1).tolist()\n","\n","        print(f\"\\nstep {step} accuracy: {accuracy_score(answer, preds):.04f}\", flush=True)\n","        save_result(output_path, preds, step)\n","\n","qa_output_path = os.path.join(\"output\", \"qa\")\n","pathlib.Path(qa_output_path).mkdir(parents=True, exist_ok=True)\n","\n","print(\"\\nevaluate on training set...\", flush=True)\n","qa_test(\n","    model_cfg=model_cfg,\n","    dataset=dataset,\n","    model_path=qa_model_path,\n","    device=device,\n","    batch_size=8,\n","    output_path=qa_output_path,\n",")\n","\n"],"execution_count":35,"outputs":[{"output_type":"stream","text":["\n","evaluate on training set...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 87/87 [00:02<00:00, 38.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","step 846 accuracy: 0.7727\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 87/87 [00:02<00:00, 39.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","step 918 accuracy: 0.8259\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 87/87 [00:02<00:00, 39.97it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","step 990 accuracy: 0.8849\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 87/87 [00:02<00:00, 40.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","step 1008 accuracy: 0.9094\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 87/87 [00:02<00:00, 39.89it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","step 1026 accuracy: 0.8993\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 87/87 [00:02<00:00, 39.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","step 1044 accuracy: 0.9094\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-a8d961104425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqa_output_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-a8d961104425>\u001b[0m in \u001b[0;36mqa_test\u001b[0;34m(model_cfg, dataset, device, batch_size, model_path, output_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mckpts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1224\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for qa_model:\n\tUnexpected key(s) in state_dict: \"qa.hid.9.weight\", \"qa.hid.9.bias\". "]}]},{"cell_type":"markdown","metadata":{"id":"kRA8QN7WNRi7"},"source":["## QA Predict"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmZIrDUHNV4T","executionInfo":{"status":"ok","timestamp":1622691737334,"user_tz":-480,"elapsed":3199,"user":{"displayName":"雷翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_p9vJEMSfuyOyiyGaAC26ss8KNNc4BGqAxWnwKw=s64","userId":"12164395439762838168"}},"outputId":"56cc8ea3-9a0f-4e59-c1d2-6131297518bd"},"source":["def qa_predict(model_cfg, dataset, device, batch_size,\n","            model_path, output_path):\n","    dataldr = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=False)\n","\n","    model = qa_model(**model_cfg, p_drop=0.0)\n","    model.load_state_dict(torch.load('exp/qa/final_model.pt'))\n","    model = model.eval().to(device)\n","\n","    preds = []\n","\n","    for batch_data in tqdm(dataldr):\n","      # answer += batch_data[\"qa_answer\"].argmax(dim=-1).tolist()\n","      pred_qa = model(\n","          document=torch.LongTensor(batch_data['article']).to(device),\n","          question=batch_data[\"question\"].to(device),\n","          choice=batch_data[\"choice\"].to(device))\n","      preds += pred_qa.argmax(dim=-1).tolist()\n","    save_result(output_path, preds, -1)\n","\n","\n","test_data = dataset_qa(\n","    vocab_path=os.path.join(\"data\", \"vocab.json\"),\n","    qa_file=os.path.join(\"data\", \"Develop_QA.json\"),\n",")\n","final_result_path=os.path.join('result','qa')\n","pathlib.Path(final_result_path).mkdir(parents=True, exist_ok=True)\n","\n","print(\"\\nevaluate on test set...\", flush=True)\n","qa_predict(\n","    model_cfg=model_cfg,\n","    dataset=test_data,\n","    model_path=qa_model_path,\n","    device=device,\n","    batch_size=8,\n","    output_path=final_result_path,\n",")"],"execution_count":37,"outputs":[{"output_type":"stream","text":["\n","evaluate on test set...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 24/24 [00:00<00:00, 36.23it/s]\n"],"name":"stderr"}]}]}